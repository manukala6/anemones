{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from math import ceil\n",
    "from shapely import wkt\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import box\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OBIS occurence data into dataframe\n",
    "raw_df = pd.read_csv('data\\OBIS_anemone_occurrences_slim.tsv', sep='\\t')\n",
    "raw_df['geometry'] = raw_df['geometry'].apply(wkt.loads)\n",
    "raw_gdf = gpd.GeoDataFrame(raw_df, geometry='geometry', crs=4326)\n",
    "\n",
    "# Transform occurence data to Behrmann projection\n",
    "behrmann_occurences_gdf = raw_gdf.to_crs(\"ESRI:54017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GBIF occurence data into dataframe\n",
    "raw_df = pd.read_csv('data\\GBIF_species_ID_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null coordinates\n",
    "raw_df = raw_df.dropna(subset=['decimalLongitude', 'decimalLatitude'])\n",
    "\n",
    "# Remove points at origin (coordinate 0, 0)\n",
    "raw_df = raw_df[(raw_df[['decimalLongitude','decimalLatitude']] != 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into geodataframe\n",
    "raw_gdf = gpd.GeoDataFrame(\n",
    "    raw_df, \n",
    "    geometry=gpd.points_from_xy(raw_df['decimalLongitude'], raw_df['decimalLatitude']),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Transform to Behrmann projection\n",
    "behrmann_raw_gdf = raw_gdf.to_crs('ESRI:54017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Natural Lands ocean map\n",
    "ocean_gdf = gpd.read_file('data\\\\ne_10m_ocean.shp', crs='ESRI:4326')\n",
    "\n",
    "# Transform to Behrmann projection\n",
    "ocean_gdf = ocean_gdf.to_crs('ESRI:54017')\n",
    "\n",
    "# Remove occurence points 10km or more inland\n",
    "ocean_10km_buffer = ocean_gdf.buffer(10000)\n",
    "occurences_gdf = behrmann_raw_gdf.clip(ocean_10km_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fishnet grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fishnet(grid_size, bbox, projection):\n",
    "    # Initialize the transformer to convert from geographic (longitude, latitude) to Behrmann projection\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", projection, always_xy=True)\n",
    "    \n",
    "    # Transform the bounding box coordinates to the projection\n",
    "    min_x, min_y = transformer.transform(bbox[0], bbox[1])\n",
    "    max_x, max_y = transformer.transform(bbox[2], bbox[3])\n",
    "    \n",
    "    # Calculate number of cells needed in the x and y directions\n",
    "    x_cells = ceil(int((max_x - min_x) / grid_size))\n",
    "    y_cells = ceil(int((max_y - min_y) / grid_size))\n",
    "    \n",
    "    # Generate polygons for each cell in the grid\n",
    "    polygons = []\n",
    "    tile_ids = []\n",
    "    for i in range(x_cells):\n",
    "        for j in range(y_cells):\n",
    "            # Coordinates of the lower left corner of the grid cell\n",
    "            x1 = min_x + i * grid_size\n",
    "            y1 = min_y + j * grid_size\n",
    "            # Create a polygon for the grid cell\n",
    "            poly = box(x1, y1, x1 + grid_size, y1 + grid_size)\n",
    "            tile_id = f\"{i}_{j}\"\n",
    "            polygons.append(poly)\n",
    "            tile_ids.append(tile_id)\n",
    "    \n",
    "    # Create a GeoDataFrame from the polygons\n",
    "    grid = gpd.GeoDataFrame({'tile_id': tile_ids, 'geometry': polygons}, crs=projection)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bounding box in geographic coordinates [min_lon, min_lat, max_lon, max_lat]\n",
    "bbox = [-180, -80, 180, 80]  # Adjust latitude as per the usability in cylindrical projections\n",
    "\n",
    "# Grid size in meters (e.g., 1000 km)\n",
    "grid_size = 800000\n",
    "\n",
    "# Create the fishnet grid\n",
    "grid = create_fishnet(grid_size, bbox, \"ESRI:54017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join occurence data to grid\n",
    "occurences_joined_gdf = occurences_gdf.sjoin(grid, how=\"inner\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = occurences_joined_gdf['tile_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subgrids and transform occurence data to incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgrid(geom):\n",
    "    min_x, min_y, max_x, max_y = geom.bounds\n",
    "    x_cells = int((max_x - min_x) / 2000)\n",
    "    y_cells = int((max_y - min_y) / 2000)\n",
    "\n",
    "    polygons = []\n",
    "    tile_ids = []\n",
    "    for i in range(x_cells):\n",
    "        for j in range(y_cells):\n",
    "            # Coordinates of the lower left corner of the grid cell\n",
    "            x1 = min_x + i * 2000\n",
    "            y1 = min_y + j * 2000\n",
    "            # Create a polygon for the grid cell\n",
    "            poly = box(x1, y1, x1 + 2000, y1 + 2000)\n",
    "            tile_id = f\"{i}_{j}\"\n",
    "            polygons.append(poly)\n",
    "            tile_ids.append(tile_id)\n",
    "\n",
    "    return gpd.GeoDataFrame({'subgrid_id': tile_ids, 'geometry': polygons}, crs='ESRI:54017')\n",
    "\n",
    "def species_counts(df):\n",
    "    return df['species'].value_counts().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbif2inext(occurences: gpd.GeoDataFrame, grid: gpd.GeoDataFrame, output_dir: str):\n",
    "\n",
    "    # Join occurence data to grid\n",
    "    joined = occurences.sjoin(grid, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "    # List of cells with occurences\n",
    "    cells = joined['tile_id'].unique().tolist()\n",
    "\n",
    "    # Maximum number of occurences in a cell\n",
    "    max_species_count = 0\n",
    "\n",
    "    # Number of sampling units\n",
    "    grid_size = int(grid['geometry'].iloc[0].bounds[3] - grid['geometry'].iloc[0].bounds[1])\n",
    "    num_sampling_units = int((grid_size / 2000) ** 2)\n",
    "\n",
    "    for cell in tqdm(cells):\n",
    "        # Get occurences in the cell\n",
    "        cell_occurences = joined[joined['tile_id'] == cell].drop('index_right', axis=1)\n",
    "\n",
    "        # Create subgrid\n",
    "        geom = grid[grid['tile_id'] == cell]['geometry'].item()\n",
    "        subgrid = create_subgrid(geom)\n",
    "\n",
    "        # Join occurences to subgrid\n",
    "        joined_subgrid = cell_occurences.sjoin(subgrid, how='inner', predicate='within').drop('index_right', axis=1)\n",
    "\n",
    "        # Identify assemblage\n",
    "        assemblage = species_counts(joined_subgrid)\n",
    "\n",
    "        # Calc species count and reset max_species_count if neededdd\n",
    "        if len(assemblage) > max_species_count:\n",
    "            max_species_count = len(assemblage)\n",
    "\n",
    "        export = pd.DataFrame(assemblage, columns=[cell])\n",
    "        sampling_unit_row = pd.DataFrame([num_sampling_units], columns=export.columns)\n",
    "        export = pd.concat([sampling_unit_row, export]).reset_index(drop=True)\n",
    "        export.to_csv(f'{output_dir}\\\\{cell}.csv', index=False)\n",
    "\n",
    "    return max_species_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c1f353c4194245afb07bca4e12e4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_species_count = gbif2inext(occurences_gdf, grid, 'inext_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend every file to max_species_count\n",
    "\n",
    "def extend_df(dir, max_species_count):\n",
    "    fps = [os.path.join(dir, f) for f in os.listdir(dir)]\n",
    "    for fp in fps:\n",
    "        df = pd.read_csv(fp)\n",
    "        diff = max_species_count - len(df)\n",
    "        if diff > 0:\n",
    "            addl_rows = pd.DataFrame([[0]*len(df.columns)]*diff, columns=df.columns)\n",
    "            df = pd.concat([df, addl_rows]).reset_index(drop=True)\n",
    "        df.to_csv(fp, index=False)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_df('inext_input', max_species_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
